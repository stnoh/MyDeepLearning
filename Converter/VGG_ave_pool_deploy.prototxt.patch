--- VGG_ave_pool_deploy.prototxt	2018-11-07 20:07:17.421487500 +0900
+++ VGG_ave_pool_deploy.prototxt	2018-11-08 23:24:37.377614900 +0900
@@ -1,331 +1,331 @@
 name: "VGG_ILSVRC_19_layers"
-input: "data"
-input_dim: 1
-input_dim: 3
-input_dim: 256
-input_dim: 256
-force_backward: true
-layers {
-  bottom: "data"
+layer {
+  name: "image"
+  type: "Input"
+  top: "image"
+  input_param {shape {dim: 1, dim: 3, dim: 256, dim: 256}}
+}
+layer {
+  bottom: "image"
   top: "conv1_1"
   name: "conv1_1"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 64
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv1_1"
   top: "conv1_1"
   name: "relu1_1"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv1_1"
   top: "conv1_2"
   name: "conv1_2"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 64
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv1_2"
   top: "conv1_2"
   name: "relu1_2"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv1_2"
   top: "pool1"
   name: "pool1"
-  type: POOLING
+  type: "Pooling"
   pooling_param {
     pool: AVE
     kernel_size: 2
     stride: 2
   }
 }
-layers {
+layer {
   bottom: "pool1"
   top: "conv2_1"
   name: "conv2_1"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 128
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv2_1"
   top: "conv2_1"
   name: "relu2_1"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv2_1"
   top: "conv2_2"
   name: "conv2_2"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 128
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv2_2"
   top: "conv2_2"
   name: "relu2_2"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv2_2"
   top: "pool2"
   name: "pool2"
-  type: POOLING
+  type: "Pooling"
   pooling_param {
     pool: AVE
     kernel_size: 2
     stride: 2
   }
 }
-layers {
+layer {
   bottom: "pool2"
   top: "conv3_1"
   name: "conv3_1"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 256
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv3_1"
   top: "conv3_1"
   name: "relu3_1"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv3_1"
   top: "conv3_2"
   name: "conv3_2"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 256
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv3_2"
   top: "conv3_2"
   name: "relu3_2"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv3_2"
   top: "conv3_3"
   name: "conv3_3"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 256
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv3_3"
   top: "conv3_3"
   name: "relu3_3"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv3_3"
   top: "conv3_4"
   name: "conv3_4"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 256
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv3_4"
   top: "conv3_4"
   name: "relu3_4"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv3_4"
   top: "pool3"
   name: "pool3"
-  type: POOLING
+  type: "Pooling"
   pooling_param {
     pool: AVE
     kernel_size: 2
     stride: 2
   }
 }
-layers {
+layer {
   bottom: "pool3"
   top: "conv4_1"
   name: "conv4_1"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 512
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv4_1"
   top: "conv4_1"
   name: "relu4_1"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv4_1"
   top: "conv4_2"
   name: "conv4_2"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 512
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv4_2"
   top: "conv4_2"
   name: "relu4_2"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv4_2"
   top: "conv4_3"
   name: "conv4_3"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 512
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv4_3"
   top: "conv4_3"
   name: "relu4_3"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv4_3"
   top: "conv4_4"
   name: "conv4_4"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 512
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv4_4"
   top: "conv4_4"
   name: "relu4_4"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv4_4"
   top: "pool4"
   name: "pool4"
-  type: POOLING
+  type: "Pooling"
   pooling_param {
     pool: AVE
     kernel_size: 2
     stride: 2
   }
 }
-layers {
+layer {
   bottom: "pool4"
   top: "conv5_1"
   name: "conv5_1"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 512
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv5_1"
   top: "conv5_1"
   name: "relu5_1"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv5_1"
   top: "conv5_2"
   name: "conv5_2"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 512
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv5_2"
   top: "conv5_2"
   name: "relu5_2"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv5_2"
   top: "conv5_3"
   name: "conv5_3"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 512
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv5_3"
   top: "conv5_3"
   name: "relu5_3"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv5_3"
   top: "conv5_4"
   name: "conv5_4"
-  type: CONVOLUTION
+  type: "Convolution"
   convolution_param {
     num_output: 512
     pad: 1
     kernel_size: 3
   }
 }
-layers {
+layer {
   bottom: "conv5_4"
   top: "conv5_4"
   name: "relu5_4"
-  type: RELU
+  type: "ReLU"
 }
-layers {
+layer {
   bottom: "conv5_4"
   top: "pool5"
   name: "pool5"
-  type: POOLING
+  type: "Pooling"
   pooling_param {
     pool: AVE
     kernel_size: 2
