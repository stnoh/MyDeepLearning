{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial 01. PyTorch vs. NumPy\n",
    "\n",
    "- 基本的に，[このチュートリアル](https://tutorials.pytorch.kr/beginner/deep_learning_60min_blitz.html)の内容に基づいている．  \n",
    "- ある程度のPython+科学技術計算経験者が早く把握のできるようにちょっと加えてみた．  \n",
    "- GPU関連の操作は，恐らく複数GPUを使わない限り実感が沸かないと判断し，除外している．  \n",
    "- 全体として，**PyTorchはNumpy機能を代替している**と要約できる．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "import numpy as np ## NumPy as comparison target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ構造\n",
    "\n",
    "PyTorchのテンソルは，基本的にNumPyの行列と思えば良い．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2602, 0.5925, 0.2110],\n",
      "        [0.2940, 0.4043, 0.2569],\n",
      "        [0.1033, 0.0964, 0.2389],\n",
      "        [0.4379, 0.6319, 0.8611],\n",
      "        [0.0877, 0.9227, 0.8046]])\n",
      "[[0.85146844 0.76726657 0.77656729]\n",
      " [0.5854232  0.26934039 0.19205566]\n",
      " [0.99524037 0.87030753 0.92522028]\n",
      " [0.63730814 0.93278414 0.0784962 ]\n",
      " [0.2918383  0.05876011 0.68389239]]\n"
     ]
    }
   ],
   "source": [
    "## declare container with random values\n",
    "x_pt = torch.rand(5, 3)\n",
    "print(x_pt)\n",
    "\n",
    "x_np = np.random.rand(5, 3)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n",
      "[5.5 3. ]\n"
     ]
    }
   ],
   "source": [
    "## conversion from list (already existing data)\n",
    "x = [5.5, 3.0]\n",
    "\n",
    "x_pt = torch.tensor(x)\n",
    "print(x_pt)\n",
    "\n",
    "x_np = np.array(x)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "## declare zero-cleared container\n",
    "x_pt = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x_pt)\n",
    "\n",
    "x_np = np.zeros([5, 3], dtype=np.long)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "(5, 3)\n"
     ]
    }
   ],
   "source": [
    "## 大きさ表示\n",
    "print(x_pt.size())\n",
    "print(x_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演算\n",
    "\n",
    "- 基本的に，NumPyで行われた多数の演算を無理なくPyTorchで出来るのを示している．\n",
    "- 複数GPUを扱う際の処理が若干気になるが，恐らくチュートリアルでやる内容でないのでこれで良いか．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9669, 0.4496, 0.3255],\n",
      "        [0.2800, 0.9695, 0.9033],\n",
      "        [0.8509, 0.9402, 0.0901],\n",
      "        [0.0302, 0.4726, 0.2825],\n",
      "        [0.6208, 0.3520, 0.2769]])\n",
      "tensor([[0.9669, 0.4496, 0.3255],\n",
      "        [0.2800, 0.9695, 0.9033],\n",
      "        [0.8509, 0.9402, 0.0901],\n",
      "        [0.0302, 0.4726, 0.2825],\n",
      "        [0.6208, 0.3520, 0.2769]])\n",
      "[[0.81128594 0.7028886  0.27452661]\n",
      " [0.52781861 0.10260228 0.79066118]\n",
      " [0.18547738 0.91515995 0.42936008]\n",
      " [0.80653872 0.91546415 0.93381   ]\n",
      " [0.61623963 0.35674746 0.15297064]]\n",
      "[[0.81128594 0.7028886  0.27452661]\n",
      " [0.52781861 0.10260228 0.79066118]\n",
      " [0.18547738 0.91515995 0.42936008]\n",
      " [0.80653872 0.91546415 0.93381   ]\n",
      " [0.61623963 0.35674746 0.15297064]]\n"
     ]
    }
   ],
   "source": [
    "## (1) Python operator (2) library's operator\n",
    "y_pt = torch.rand(5, 3)\n",
    "print(x_pt + y_pt)\n",
    "print(torch.add(x_pt, y_pt))\n",
    "\n",
    "y_np = np.random.rand(5, 3)\n",
    "print(x_np + y_np)\n",
    "print(np.add(x_np, y_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9669, 0.4496, 0.3255],\n",
      "        [0.2800, 0.9695, 0.9033],\n",
      "        [0.8509, 0.9402, 0.0901],\n",
      "        [0.0302, 0.4726, 0.2825],\n",
      "        [0.6208, 0.3520, 0.2769]])\n",
      "[[0.81128594 0.7028886  0.27452661]\n",
      " [0.52781861 0.10260228 0.79066118]\n",
      " [0.18547738 0.91515995 0.42936008]\n",
      " [0.80653872 0.91546415 0.93381   ]\n",
      " [0.61623963 0.35674746 0.15297064]]\n"
     ]
    }
   ],
   "source": [
    "## use \"out\" argument\n",
    "result_pt = torch.empty(5, 3)\n",
    "torch.add(x_pt, y_pt, out=result_pt)\n",
    "print(result_pt)\n",
    "\n",
    "result_np = np.empty([5, 3])\n",
    "np.add(x_np, y_np, out=result_np)\n",
    "print(result_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9669, 0.4496, 0.3255],\n",
      "        [0.2800, 0.9695, 0.9033],\n",
      "        [0.8509, 0.9402, 0.0901],\n",
      "        [0.0302, 0.4726, 0.2825],\n",
      "        [0.6208, 0.3520, 0.2769]])\n",
      "[[0.81128594 0.7028886  0.27452661]\n",
      " [0.52781861 0.10260228 0.79066118]\n",
      " [0.18547738 0.91515995 0.42936008]\n",
      " [0.80653872 0.91546415 0.93381   ]\n",
      " [0.61623963 0.35674746 0.15297064]]\n"
     ]
    }
   ],
   "source": [
    "## in-place operations\n",
    "y_pt.add_(x_pt)\n",
    "print(y_pt)\n",
    "\n",
    "y_np.__iadd__(x_np)\n",
    "print(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4496, 0.9695, 0.9402, 0.4726, 0.3520])\n",
      "[0.7028886  0.10260228 0.91515995 0.91546415 0.35674746]\n"
     ]
    }
   ],
   "source": [
    "## indexing\n",
    "print(y_pt[:, 1])\n",
    "print(y_np[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "(4, 4) (16,) (2, 8)\n"
     ]
    }
   ],
   "source": [
    "## PyTorch: view\n",
    "x_pt = torch.randn(4, 4)\n",
    "y_pt = x_pt.view(16)\n",
    "z_pt = x_pt.view(-1, 8)\n",
    "print(x_pt.size(), y_pt.size(), z_pt.size())\n",
    "\n",
    "## NumPy: reshape\n",
    "x_np = np.random.randn(4, 4)\n",
    "y_np = x_np.reshape(16)\n",
    "z_np = x_np.reshape(-1, 8)\n",
    "print(x_np.shape, y_np.shape, z_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1095])\n",
      "0.1095004677772522\n",
      "[-0.55731927]\n",
      "-0.5573192692657932\n"
     ]
    }
   ],
   "source": [
    "## direct access to the value (not container)\n",
    "x_pt = torch.randn(1)\n",
    "print(x_pt) ## with \"tensor\"\n",
    "print(x_pt.item())\n",
    "\n",
    "x_np = np.random.randn(1)\n",
    "print(x_np) ## with \"[]\"\n",
    "print(x_np.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorchとNumPy間の変換\n",
    "\n",
    "- 明示的に言っていないが，２つの種類がある模様．\n",
    "- 抽出(PyTorchからNumPy)する方法: 後の変化が反映されない (?)\n",
    "- バインド(NumPyからPyTorch)する方法: 後の変化が反映される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "## one-way exporting (PyTorch -> NumPy)\n",
    "a_pt = torch.ones(5)\n",
    "print(a_pt)\n",
    "\n",
    "b_np = a_pt.numpy() ## exporting: just export as NumPy data\n",
    "print(b_np)\n",
    "\n",
    "## after exporting, changes in PyTorch does not affect to NumPy data\n",
    "a_pt = a_pt + a_pt\n",
    "print(a_pt)\n",
    "print(b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## binding (NumPy-PyTorch)\n",
    "a_np = np.ones(5)\n",
    "print(a_np)\n",
    "b_pt = torch.from_numpy(a_np) ## binding a (NumPy) and b (PyTorch)\n",
    "print(b_pt)\n",
    "\n",
    "## after binding, changes in NumPy also transferred to PyTorch\n",
    "np.add(a_np, 1, out=a_np)\n",
    "print(a_np)\n",
    "print(b_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors\n",
    "\n",
    "- CPU<->GPUや，GPU間の転送に使われる(?)\n",
    "- まだ完璧でなく，CUDAしか対応できない模様..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1095], device='cuda:0')\n",
      "tensor([1.1095], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y_pt = torch.ones_like(x_pt, device=device) ## option (1)\n",
    "    x_pt = x_pt.to(device)                      ## option (2)\n",
    "    z_pt = x_pt + y_pt\n",
    "    print(z_pt)\n",
    "    print(z_pt.to(\"cpu\", torch.double))         ## send to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
